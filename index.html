<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alim Gumran</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <main class="container">
        <section id="about">
            <img src="try.jpg" alt="Alim Gumran" class="profile-image">
            <h1 class="name">Alim Gumran</h1>
            <p>
                I am a machine learning researcher specializing in interpretability and safety.
                Currently, I am working on reinforcement learning at <a href="https://www.aisafety.camp/">AI Safety Camp</a>.
                I have coauthored a research article on mechanistic interpretability, currently under review at ICML 2025.
                Previously, I worked as a machine learning engineer in the industry, focusing on image and video processing.
                
                In Fall 2025, I am set to start my Master's studies in computer science at <a href="https://www.ens-lyon.fr/">École normale supérieure de Lyon</a>, France.
                At the moment, I am finishing a Bachelor's program in mathematics at <a href="https://nu.edu.kz/">Nazarbayev University</a>, Kazakhstan.
            </p>
            <div class="contact-links">
                <a href="https://drive.google.com/file/d/1FlCe8SN12WYkfm6ZFlnMxnLF1ViY4DVv/view?usp=sharing" id="cv">CV/Resume</a> |
                <a href="https://www.linkedin.com/in/gumran/" id="linkedin">LinkedIn</a> |
                <a href="https://github.com/gumran" id="github">GitHub</a> |
                <a href="https://scholar.google.com/citations?user=99g_TL0AAAAJ" id="scholar">Google Scholar</a>

            </div>
            <p>a.r.gumran@gmail.com</p>
        </section>

        <section id="research">
            <h2>Research</h2>
            <div class="research-list">
                <article class="research-card">
                    <h3>Compute Optimal Inference and Provable Amortisation Gap in Sparse Autoencoders</h3>
                    <p>
                        Limitations of sparse autoencoders in mechanistic interpretability.
                        <br>The paper is available <a href="https://arxiv.org/abs/2411.13117">here</a>.
                    </p>
                </article>
                <article class="research-card">
                    <h3>Scalable Soft Optimization</h3>
                    <p>
                        Reward hacking mitigation in deep reinforcement learning.
                        <br>The project outline is available <a href="https://docs.google.com/document/d/1jfNKhIRAO1CFPliKsLlL5lcXZO_z-u2gLUilpE19GS8/edit?tab=t.0#heading=h.9lmc73wscx1r">here</a>.
                    </p>
                </article>
                <article class="research-card">
                    <h3>Learned Representations in Drug Discovery</h3>
                    <p>
                        Representations in graph neural networks for drug-target affinity.
                        <br>In progress.
                    </p>
                </article>
            </div>
        </section>
    </main>
</body>
</html>