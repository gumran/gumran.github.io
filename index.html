<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alim Gumran</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

    <main class="container">
        <section id="about">
            <img src="image.jpg" alt="Alim Gumran" class="profile-image" style="width: 150px; height: auto;">
            <h1 class="name" style="font-size: 2.0em;">Alim Gumran</h1>
            <p>
                I am a machine learning researcher focused on interpretability and safety.
                I currently participate at <a href="https://www.aisafety.camp/">AI Safety Camp</a>, where I work on reinforcement learning.
                Previously, I worked in the industry as a machine learning engineer specializing in image and video processing.
                <br><br>
                In Fall 2025, I am set to start my Master's studies in computer science at <a href="https://www.ens-lyon.fr/">École normale supérieure de Lyon</a>, France.
                At the moment, I am finishing a Bachelor's program in mathematics at <a href="https://nu.edu.kz/">Nazarbayev University</a>, Kazakhstan.
            </p>
            <div class="contact-links">
                <a href="https://www.linkedin.com/in/gumran/" id="linkedin"><b>LinkedIn</b></a> |
                <a href="https://github.com/gumran" id="github"><b>GitHub</b></a> |
                <a href="https://docs.google.com/document/d/1kw1SIWEosb4gHaWduSYpCV57riWTPqei5-Vqjp0d0Lc/edit?usp=sharing" id="cv"><b>CV/Resume</b></a> |
                <a id="email">a.r.gumran@gmail.com</a>
            </div>

        
        </section>

        

        <section id="research">
            <h2>Research</h2>
            <div class="research-list">
                <article class="research-card">
                    <h3>Compute Optimal Inference and Provable Amortisation Gap in Sparse Autoencoders</h3>
                    <p>
                        Limitations of sparse autoencoders in mechanistic interpretability.
                        <br>The paper is available <a href="https://arxiv.org/abs/2411.13117">here</a>.
                    </p>
                </article>
                <article class="research-card">
                    <h3>Scalable Soft Optimization</h3>
                    <p>
                        Reward hacking mitigation in deep reinforcement learning.
                        <br>The project outline is available <a href="https://docs.google.com/document/d/1jfNKhIRAO1CFPliKsLlL5lcXZO_z-u2gLUilpE19GS8/edit?tab=t.0#heading=h.9lmc73wscx1r">here</a>.
                    </p>
                </article>
                <article class="research-card">
                    <h3>Learned Representations in Drug Discovery</h3>
                    <p>
                        Representations in graph neural networks for drug-target affinity.
                        <br>In progress.
                    </p>
                </article>
            </div>
        </section>
    </main>

</body>
</html>